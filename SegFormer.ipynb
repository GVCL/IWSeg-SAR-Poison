{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset, Image\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor, TrainingArguments, Trainer\n",
    "from PIL import Image as PILImage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import glob\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "IMAGE_SIZE = (512, 512)  # Resize images to this size\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 5e-5\n",
    "VAL_SPLIT = 0.125\n",
    "\n",
    "id2label = {0: 'background', 1: 'water'}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "NUM_CLASSES = len(id2label)\n",
    "\n",
    "MODEL_CHECKPOINT = 'nvidia/mit-b4'\n",
    "\n",
    "# Check GPU availability\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=NUM_CLASSES,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# Load Pretrained SegFormer with 2 Classes\n",
    "\n",
    "processor = SegformerImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "# model = SegformerForSemanticSegmentation.from_pretrained(model_name, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Modify the classifier head\n",
    "# model.config.num_labels = NUM_CLASSES\n",
    "# model.decode_head.classifier = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = \"./sar_images/images/train/*.png\"\n",
    "train_mask_dir = \"./sar_images/masks/train/*.png\"\n",
    "test_image_dir = \"./sar_images/images/test\"\n",
    "test_mask_dir = \"./sar_images/masks/test\"\n",
    "\n",
    "images = list(glob.glob(train_image_dir))\n",
    "# images = [str(path) for path in images]\n",
    "masks = [path.replace('/images', '/masks') for path in images]\n",
    "\n",
    "print(images)\n",
    "print(masks)\n",
    "\n",
    "print(f'{len(images)} images detected.')\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    images, masks, test_size=VAL_SPLIT, random_state=0, shuffle=True)\n",
    "\n",
    "print(f'Train images: {len(train_images)}\\nValidation images: {len(val_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_as_rgb(image_path):\n",
    "    # Open image\n",
    "    img = PILImage.open(image_path)\n",
    "    \n",
    "    # If the image is grayscale (mode 'L'), convert it to RGB\n",
    "    if img.mode == 'L':\n",
    "        img = img.convert('RGB')  # Convert grayscale to RGB\n",
    "    return img\n",
    "\n",
    "def load_mask_as_binary(mask_path):\n",
    "    # Open mask image (keep it in grayscale)\n",
    "    mask = PILImage.open(mask_path)\n",
    "\n",
    "    # Convert to grayscale (if not already in mode 'L')\n",
    "    if mask.mode != 'L':\n",
    "        mask = mask.convert('L')\n",
    "    \n",
    "    # Convert mask values from 0-255 to 0-1 (binary)\n",
    "    mask = np.array(mask)  # Convert to NumPy array\n",
    "    mask[mask == 255] = 1   # Replace 255 with 1\n",
    "    mask[mask == 0] = 0     # Ensure 0 stays as 0\n",
    "    \n",
    "    # Convert back to PIL Image for compatibility\n",
    "    mask = PILImage.fromarray(mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def create_dataset(image_paths, mask_paths):\n",
    "    # Apply the custom loader for RGB images and grayscale masks\n",
    "    image_paths_rgb = [load_image_as_rgb(img_path) for img_path in image_paths]\n",
    "    mask_paths_gray = [load_mask_as_binary(mask_path) for mask_path in mask_paths]\n",
    "    \n",
    "    # Create dataset from image paths and mask paths\n",
    "    dataset = Dataset.from_dict({'pixel_values': image_paths_rgb,\n",
    "                                 'label': mask_paths_gray})\n",
    "    \n",
    "    # Ensure images are loaded as Image() format (from PIL images)\n",
    "    dataset = dataset.cast_column('pixel_values', Image())\n",
    "    dataset = dataset.cast_column('label', Image())  # Keep masks as grayscale images\n",
    "    return dataset\n",
    "\n",
    "# Usage\n",
    "ds_train = create_dataset(train_images, train_masks)\n",
    "ds_valid = create_dataset(val_images, val_masks)\n",
    "\n",
    "def apply_transforms(batch):\n",
    "    images = [x for x in batch['pixel_values']]\n",
    "    labels = [x for x in batch['label']]\n",
    "    \n",
    "    # Convert PIL images to NumPy arrays for processing\n",
    "    images = [np.array(image) for image in images]\n",
    "    labels = [np.array(label) for label in labels]\n",
    "    \n",
    "    # print(labels)    \n",
    "\n",
    "    inputs = processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "ds_train.set_transform(apply_transforms)\n",
    "ds_valid.set_transform(apply_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('mean_iou')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        print(labels.shape[-2:])\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        # scale the logits to the size of the label\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode='bilinear',\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        # currently using _compute instead of compute\n",
    "        # see this issue for more info: https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n",
    "        metrics = metric._compute(\n",
    "                predictions=pred_labels,\n",
    "                references=labels,\n",
    "                num_labels=len(id2label),\n",
    "                ignore_index=None,\n",
    "                reduce_labels=processor.do_reduce_labels,\n",
    "            )\n",
    "\n",
    "        # add per category metrics as individual key-value pairs\n",
    "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='segformer_water_finetuned',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    save_total_limit=3,\n",
    "    # eval_strategy='steps',\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    # save_steps=20,\n",
    "    # eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('segformer_water')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

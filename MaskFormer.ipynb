{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset, Image\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoImageProcessor, MaskFormerForInstanceSegmentation, TrainingArguments, Trainer, MaskFormerConfig, MaskFormerModel\n",
    "from PIL import Image as PILImage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from typing import Dict, List, Mapping\n",
    "from transformers.trainer import EvalPrediction\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\utils\\deprecation.py:172: UserWarning: The following named arguments are not valid for `MaskFormerImageProcessor.__init__` and were ignored: '_max_size'\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskFormerForInstanceSegmentation(\n",
       "  (model): MaskFormerModel(\n",
       "    (pixel_level_module): MaskFormerPixelLevelModule(\n",
       "      (encoder): ResNetBackbone(\n",
       "        (embedder): ResNetEmbeddings(\n",
       "          (embedder): ResNetConvLayer(\n",
       "            (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "            (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (encoder): ResNetEncoder(\n",
       "          (stages): ModuleList(\n",
       "            (0): ResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): ResNetBottleNeckLayer(\n",
       "                  (shortcut): ResNetShortCut(\n",
       "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): ResNetBottleNeckLayer(\n",
       "                  (shortcut): ResNetShortCut(\n",
       "                    (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): ResNetBottleNeckLayer(\n",
       "                  (shortcut): ResNetShortCut(\n",
       "                    (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (4): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (5): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): ResNetBottleNeckLayer(\n",
       "                  (shortcut): ResNetShortCut(\n",
       "                    (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): ResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): MaskFormerPixelDecoder(\n",
       "        (fpn): MaskFormerFPNModel(\n",
       "          (stem): MaskFormerFPNConvLayer(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): MaskFormerFPNLayer(\n",
       "              (proj): Sequential(\n",
       "                (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (block): MaskFormerFPNConvLayer(\n",
       "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): MaskFormerFPNLayer(\n",
       "              (proj): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (block): MaskFormerFPNConvLayer(\n",
       "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): MaskFormerFPNLayer(\n",
       "              (proj): Sequential(\n",
       "                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (block): MaskFormerFPNConvLayer(\n",
       "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mask_projection): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (transformer_module): MaskFormerTransformerModule(\n",
       "      (position_embedder): MaskFormerSinePositionEmbedding()\n",
       "      (queries_embedder): Embedding(100, 256)\n",
       "      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (decoder): DetrDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x DetrDecoderLayer(\n",
       "            (self_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (class_predictor): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (mask_embedder): MaskformerMLPPredictionHead(\n",
       "    (0): PredictionBlock(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): PredictionBlock(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): PredictionBlock(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (matcher): Matcher MaskFormerHungarianMatcher\n",
       "      cost_class: 1.0\n",
       "      cost_mask: 20.0\n",
       "      cost_dice: 1.0\n",
       "  (criterion): MaskFormerLoss(\n",
       "    (matcher): Matcher MaskFormerHungarianMatcher\n",
       "        cost_class: 1.0\n",
       "        cost_mask: 20.0\n",
       "        cost_dice: 1.0\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "IMAGE_SIZE = (512, 512)  # Resize images to this size\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 5e-5\n",
    "VAL_SPLIT = 0.125\n",
    "\n",
    "id2label = {0: 'background', 1: 'water'}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "NUM_CLASSES = len(id2label)\n",
    "\n",
    "MODEL_CHECKPOINT = \"facebook/maskformer-resnet50-coco-stuff\"\n",
    "\n",
    "config = MaskFormerConfig.from_pretrained(MODEL_CHECKPOINT)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "config.num_labels = NUM_CLASSES\n",
    "\n",
    "# Use the config object to initialize a MaskFormer model with randomized weights\n",
    "model = MaskFormerForInstanceSegmentation(config)\n",
    "\n",
    "base_model = MaskFormerModel.from_pretrained(MODEL_CHECKPOINT)\n",
    "model.model = base_model\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 883\n",
      "Validation images: 127\n"
     ]
    }
   ],
   "source": [
    "train_image_dir = \"./sar_images/images/train/*.png\"\n",
    "train_mask_dir = \"./sar_images/masks/train/*.png\"\n",
    "test_image_dir = \"./sar_images/images/test\"\n",
    "test_mask_dir = \"./sar_images/masks/test\"\n",
    "\n",
    "images = list(glob.glob(train_image_dir))\n",
    "# images = [str(path) for path in images]\n",
    "masks = [path.replace('/images', '/masks') for path in images]\n",
    "\n",
    "# print(images)\n",
    "# print(masks)\n",
    "\n",
    "# print(f'{len(images)} images detected.')\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    images, masks, test_size=VAL_SPLIT, random_state=0, shuffle=True)\n",
    "\n",
    "print(f'Train images: {len(train_images)}\\nValidation images: {len(val_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_as_rgb(image_path):\n",
    "    # Open image\n",
    "    img = PILImage.open(image_path)\n",
    "    \n",
    "    # If the image is grayscale (mode 'L'), convert it to RGB\n",
    "    if img.mode == 'L':\n",
    "        img = img.convert('RGB')  # Convert grayscale to RGB\n",
    "    return img\n",
    "\n",
    "def load_mask_as_binary(mask_path):\n",
    "    # Open mask image (keep it in grayscale)\n",
    "    mask = PILImage.open(mask_path)\n",
    "\n",
    "    # Convert to grayscale (if not already in mode 'L')\n",
    "    if mask.mode != 'L':\n",
    "        mask = mask.convert('L')\n",
    "    \n",
    "    # Convert mask values from 0-255 to 0-1 (binary)\n",
    "    mask = np.array(mask)  # Convert to NumPy array\n",
    "    mask[mask == 255] = 1   # Replace 255 with 1\n",
    "    # mask[mask == 0] = 0     # Ensure 0 stays as 0\n",
    "    \n",
    "    # Convert back to PIL Image for compatibility\n",
    "    mask = PILImage.fromarray(mask)\n",
    "    \n",
    "    # mask = mask[np.newaxis, :, :]\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def create_dataset(image_paths, mask_paths):\n",
    "    \"\"\"Creates a dataset storing file paths as individual strings, not lists\"\"\"\n",
    "    return Dataset.from_dict({\"pixel_values\": image_paths, \"label\": mask_paths})\n",
    "\n",
    "# Create dataset from file paths\n",
    "ds_train = create_dataset(train_images, train_masks)\n",
    "ds_valid = create_dataset(val_images, val_masks)\n",
    "\n",
    "def transform(example):\n",
    "    \"\"\"Loads images/masks from file paths and applies transformations.\"\"\"\n",
    "    \n",
    "    # Apply transformation to each item in the batch\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # print(\"batch\")\n",
    "    \n",
    "    for img_path, mask_path in zip(example[\"pixel_values\"], example[\"label\"]):\n",
    "        # Open images and masks\n",
    "        image = PILImage.open(img_path).convert(\"RGB\")\n",
    "        mask = PILImage.open(mask_path).convert(\"L\")  # Convert mask to grayscale\n",
    "        \n",
    "        # Transform image\n",
    "        image = transforms.Compose([\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])(image)\n",
    "        \n",
    "        mask = np.array(mask)  # Convert to NumPy array\n",
    "        mask[mask == 255] = 1   # Replace 255 with 1\n",
    "        # print(mask)\n",
    "        # mask[mask == 0] = 0     # Ensure 0 stays as 0\n",
    "        \n",
    "        # # Convert back to PIL Image for compatibility\n",
    "        mask = PILImage.fromarray(mask)\n",
    "\n",
    "        # # Transform mask (nearest neighbor interpolation for segmentation)\n",
    "        mask = transforms.Compose([\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])(mask).long().squeeze(0)  # Convert to tensor and remove extra channel\n",
    "\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "        \n",
    "        # print(f\"Image shape: {image.shape}, Mask shape: {mask.shape}\")\n",
    "    \n",
    "    inputs = processor(images, segmentation_maps=masks, return_tensors='pt')\n",
    "    return inputs\n",
    "\n",
    "# Apply transformation correctly\n",
    "ds_train.set_transform(transform)\n",
    "ds_valid.set_transform(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = evaluate.load('mean_iou')\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     with torch.no_grad():\n",
    "#         logits, labels = eval_pred\n",
    "        \n",
    "#         if isinstance(logits, tuple):\n",
    "#             for i, logit in enumerate(logits):\n",
    "#                 print(f\"Logits[{i}] shape: {logit.shape}\")\n",
    "        \n",
    "#         if isinstance(labels, tuple):\n",
    "#             for i, label in enumerate(labels):\n",
    "#                 print(f\"Labels[{i}] shape: {label.shape}\")\n",
    "\n",
    "#         logits_tensor = torch.from_numpy(logits[1])\n",
    "#         # logits_tensor = torch.from_numpy(logits)\n",
    "#         # scale the logits to the size of the label\n",
    "        \n",
    "#         logits_tensor = nn.functional.interpolate(\n",
    "#             logits_tensor,\n",
    "#             size=IMAGE_SIZE,\n",
    "#             mode='bilinear',\n",
    "#             align_corners=False,\n",
    "#         ).argmax(dim=1)\n",
    "\n",
    "#         pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        \n",
    "#         labels_tensor = torch.from_numpy(labels[0])\n",
    "#         labels_tensor = nn.functional.interpolate(\n",
    "#             labels_tensor.float(), size=IMAGE_SIZE, mode=\"nearest\"\n",
    "#         ).long()\n",
    "        \n",
    "#         labels_resized = labels_tensor.squeeze(1).detach().cpu().numpy()\n",
    "        \n",
    "#         # currently using _compute instead of compute\n",
    "#         # see this issue for more info: https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n",
    "#         metrics = metric._compute(\n",
    "#             predictions=pred_labels,\n",
    "#             references=labels_resized,\n",
    "#             num_labels=len(id2label),\n",
    "#             ignore_index=None,\n",
    "#             reduce_labels=processor.do_reduce_labels,\n",
    "#         )\n",
    "\n",
    "#         # add per category metrics as individual key-value pairs\n",
    "#         per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "#         per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "#         metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "#         metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "#         return metrics\n",
    "\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    class_queries_logits: torch.Tensor\n",
    "    masks_queries_logits: torch.Tensor\n",
    "\n",
    "def nested_cpu(tensors):\n",
    "    if isinstance(tensors, (list, tuple)):\n",
    "        return type(tensors)(nested_cpu(t) for t in tensors)\n",
    "    elif isinstance(tensors, Mapping):\n",
    "        return type(tensors)({k: nested_cpu(t) for k, t in tensors.items()})\n",
    "    elif isinstance(tensors, torch.Tensor):\n",
    "        return tensors.cpu().detach()\n",
    "    else:\n",
    "        return tensors\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Compute metrics for the instance segmentation task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_processor: AutoImageProcessor,\n",
    "        id2label: Mapping[int, str],\n",
    "        threshold: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with image processor, id2label mapping and threshold for filtering predictions.\n",
    "\n",
    "        Args:\n",
    "            image_processor (AutoImageProcessor): Image processor for\n",
    "                `post_process_instance_segmentation` method.\n",
    "            id2label (Mapping[int, str]): Mapping from class id to class name.\n",
    "            threshold (float): Threshold to filter predicted boxes by confidence. Defaults to 0.0.\n",
    "        \"\"\"\n",
    "        self.image_processor = image_processor\n",
    "        self.id2label = id2label\n",
    "        self.threshold = threshold\n",
    "        self.metric = self.get_metric()\n",
    "\n",
    "    def get_metric(self):\n",
    "        metric = MeanAveragePrecision(iou_type=\"segm\", class_metrics=True)\n",
    "        return metric\n",
    "\n",
    "    def reset_metric(self):\n",
    "        self.metric.reset()\n",
    "\n",
    "    def postprocess_target_batch(self, target_batch) -> List[Dict[str, torch.Tensor]]:\n",
    "        \"\"\"Collect targets in a form of list of dictionaries with keys \"masks\", \"labels\".\"\"\"\n",
    "        batch_masks = target_batch[0]\n",
    "        batch_labels = target_batch[1]\n",
    "        post_processed_targets = []\n",
    "        for masks, labels in zip(batch_masks, batch_labels):\n",
    "            if not isinstance(masks, torch.Tensor):\n",
    "                masks = torch.tensor(masks)\n",
    "    \n",
    "            post_processed_targets.append(\n",
    "                {\n",
    "                    \"masks\": masks.to(dtype=torch.bool),\n",
    "                    \"labels\": labels,\n",
    "                }\n",
    "            )\n",
    "        return post_processed_targets\n",
    "\n",
    "    def get_target_sizes(self, post_processed_targets) -> List[List[int]]:\n",
    "        target_sizes = []\n",
    "        for target in post_processed_targets:\n",
    "            target_sizes.append(target[\"masks\"].shape[-2:])\n",
    "        return target_sizes\n",
    "\n",
    "    def postprocess_prediction_batch(self, prediction_batch, target_sizes) -> List[Dict[str, torch.Tensor]]:\n",
    "        \"\"\"Collect predictions in a form of list of dictionaries with keys \"masks\", \"labels\", \"scores\".\"\"\"\n",
    "        \n",
    "        class_queries_logits = prediction_batch[0]\n",
    "        masks_queries_logits = prediction_batch[1]\n",
    "        if not isinstance(class_queries_logits, torch.Tensor):\n",
    "            class_queries_logits = torch.tensor(class_queries_logits)\n",
    "        \n",
    "        if not isinstance(masks_queries_logits, torch.Tensor):\n",
    "            masks_queries_logits = torch.tensor(masks_queries_logits)\n",
    "        \n",
    "        print(\"Here 1\")\n",
    "\n",
    "        model_output = ModelOutput(class_queries_logits=class_queries_logits, masks_queries_logits=masks_queries_logits)\n",
    "        post_processed_output = self.image_processor.post_process_instance_segmentation(\n",
    "            model_output,\n",
    "            threshold=self.threshold,\n",
    "            target_sizes=target_sizes,\n",
    "            return_binary_maps=True,\n",
    "        )\n",
    "        \n",
    "        print(\"Here 2\")\n",
    "\n",
    "        post_processed_predictions = []\n",
    "        for image_predictions, target_size in zip(post_processed_output, target_sizes):\n",
    "            if image_predictions[\"segments_info\"]:\n",
    "                if not isinstance(image_predictions[\"segmentation\"], torch.Tensor):\n",
    "                    image_predictions[\"segmentation\"] = torch.tensor(image_predictions[\"segmentation\"])\n",
    "                    \n",
    "                post_processed_image_prediction = {\n",
    "                    \"masks\": image_predictions[\"segmentation\"].to(dtype=torch.bool),\n",
    "                    \"labels\": torch.tensor([x[\"label_id\"] for x in image_predictions[\"segments_info\"]]),\n",
    "                    \"scores\": torch.tensor([x[\"score\"] for x in image_predictions[\"segments_info\"]]),\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                # for void predictions, we need to provide empty tensors\n",
    "                post_processed_image_prediction = {\n",
    "                    \"masks\": torch.zeros([0, *target_size], dtype=torch.bool),\n",
    "                    \"labels\": torch.tensor([]),\n",
    "                    \"scores\": torch.tensor([]),\n",
    "                }\n",
    "            post_processed_predictions.append(post_processed_image_prediction)\n",
    "\n",
    "        return post_processed_predictions\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, evaluation_results: EvalPrediction, compute_result: bool = True) -> Mapping[str, float]:\n",
    "        \"\"\"\n",
    "        Update metrics with current evaluation results and return metrics if `compute_result` is True.\n",
    "\n",
    "        Args:\n",
    "            evaluation_results (EvalPrediction): Predictions and targets from evaluation.\n",
    "            compute_result (bool): Whether to compute and return metrics.\n",
    "\n",
    "        Returns:\n",
    "            Mapping[str, float]: Metrics in a form of dictionary {<metric_name>: <metric_value>}\n",
    "        \"\"\"\n",
    "        prediction_batch = nested_cpu(evaluation_results.predictions)\n",
    "        target_batch = nested_cpu(evaluation_results.label_ids)\n",
    "        print(\"Checkpoint 1\")\n",
    "\n",
    "        # For metric computation we need to provide:\n",
    "        #  - targets in a form of list of dictionaries with keys \"masks\", \"labels\"\n",
    "        #  - predictions in a form of list of dictionaries with keys \"masks\", \"labels\", \"scores\"\n",
    "        post_processed_targets = self.postprocess_target_batch(target_batch)\n",
    "        print(\"Checkpoint 2\")\n",
    "        target_sizes = self.get_target_sizes(post_processed_targets)\n",
    "        print(\"Checkpoint 3\")\n",
    "        post_processed_predictions = self.postprocess_prediction_batch(prediction_batch, target_sizes)\n",
    "\n",
    "        print(\"Checkpoint 4\")\n",
    "        \n",
    "        # Compute metrics\n",
    "        \n",
    "        if not isinstance(post_processed_targets, torch.Tensor):\n",
    "            post_processed_targets = torch.tensor(post_processed_targets)\n",
    "        \n",
    "        if not isinstance(post_processed_predictions, torch.Tensor):\n",
    "            post_processed_predictions = torch.tensor(post_processed_predictions)\n",
    "        \n",
    "        self.metric.update(post_processed_predictions, post_processed_targets)\n",
    "\n",
    "        print(\"Checkpoint 5\")\n",
    "        if not compute_result:\n",
    "            return\n",
    "\n",
    "        metrics = self.metric.compute()\n",
    "        \n",
    "        print(\"Checkpoint 6\")\n",
    "\n",
    "        # Replace list of per class metrics with separate metric for each class\n",
    "        classes = metrics.pop(\"classes\")\n",
    "        map_per_class = metrics.pop(\"map_per_class\")\n",
    "        mar_100_per_class = metrics.pop(\"mar_100_per_class\")\n",
    "        for class_id, class_map, class_mar in zip(classes, map_per_class, mar_100_per_class):\n",
    "            class_name = self.id2label[class_id.item()] if self.id2label is not None else class_id.item()\n",
    "            metrics[f\"map_{class_name}\"] = class_map\n",
    "            metrics[f\"mar_100_{class_name}\"] = class_mar\n",
    "\n",
    "        metrics = {k: round(v.item(), 4) for k, v in metrics.items()}\n",
    "\n",
    "        # Reset metric for next evaluation\n",
    "        self.reset_metric()\n",
    "        \n",
    "        print(\"Checkpoint 7\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='5500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   8/5500 00:08 < 2:05:50, 0.73 it/s, Epoch 0.06/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_metrics = Evaluator(image_processor=processor, id2label=id2label, threshold=0.0)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"maskformer_water_finetuned\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    # dataloader_num_workers=8,\n",
    "    # dataloader_persistent_workers=True,\n",
    "    # dataloader_prefetch_factor=4,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_accumulation_steps=5,\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('maskformer_water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SegmentationDataset(Dataset):\n",
    "#     def __init__(self, image_dir, mask_dir, processor):\n",
    "#         self.image_dir = image_dir\n",
    "#         self.mask_dir = mask_dir\n",
    "#         self.processor = processor\n",
    "#         self.image_filenames = sorted(os.listdir(image_dir))\n",
    "#         self.mask_filenames = sorted(os.listdir(mask_dir))\n",
    "        \n",
    "#         print(self.image_filenames)\n",
    "#         print(self.mask_filenames)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_filenames)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "#         mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
    "\n",
    "#         # Load and preprocess image\n",
    "#         image = Image.open(img_path).convert(\"RGB\").resize(IMAGE_SIZE)\n",
    "#         image = np.array(image) / 255.0  # Normalize\n",
    "\n",
    "#         # Load and preprocess mask\n",
    "#         mask = Image.open(mask_path).resize(IMAGE_SIZE)  # Nearest-neighbor for masks\n",
    "#         mask = np.array(mask) / 255\n",
    "        \n",
    "#         # Ensure mask is single channel\n",
    "#         if len(mask.shape) == 3:\n",
    "#             mask = mask[:, :, 0]\n",
    "\n",
    "#         # Convert image to model format\n",
    "#         inputs = self.processor(image, return_tensors=\"pt\")\n",
    "#         pixel_values = inputs[\"pixel_values\"].squeeze(0)  # Remove batch dimension\n",
    "\n",
    "#         # Convert mask to tensor (0 and 1 for binary classification)\n",
    "#         mask = torch.tensor(mask, dtype=torch.long)  # Shape: (512, 512)\n",
    "\n",
    "#         return pixel_values, mask\n",
    "\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, image_dir, processor):\n",
    "#         self.image_dir = image_dir\n",
    "#         self.processor = processor\n",
    "#         self.image_filenames = sorted(os.listdir(image_dir))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_filenames)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "\n",
    "#         # Load and preprocess image\n",
    "#         image = Image.open(img_path).convert(\"RGB\").resize(IMAGE_SIZE)\n",
    "#         image_array = np.array(image) / 255.0  # Normalize\n",
    "\n",
    "#         # Convert image to model format\n",
    "#         inputs = self.processor(image_array, return_tensors=\"pt\")\n",
    "#         pixel_values = inputs[\"pixel_values\"].squeeze(0)  # Remove batch dimension\n",
    "\n",
    "#         return pixel_values, self.image_filenames[idx]  # Return filename to save output later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset = SegmentationDataset(train_image_dir, train_mask_dir, processor)\n",
    "\n",
    "# # Split into Train and Validation\n",
    "# train_size = int((1 - VAL_SPLIT) * len(full_dataset))\n",
    "# val_size = len(full_dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# # Create DataLoaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     model.train()\n",
    "#     total_train_loss = 0\n",
    "\n",
    "#     for step, (images, masks) in enumerate(train_loader):\n",
    "#         images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # No mixed precision (removed torch.amp.autocast and GradScaler)\n",
    "#         outputs = model(pixel_values=images).logits  # Shape: (B, C, H, W)\n",
    "#         outputs = F.interpolate(outputs, size=IMAGE_SIZE, mode=\"bilinear\", align_corners=False)  # Resize to match masks\n",
    "#         loss = criterion(outputs, masks)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_train_loss += loss.item()\n",
    "\n",
    "#     # Validation Loop\n",
    "#     model.eval()\n",
    "#     total_val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, masks in val_loader:\n",
    "#             images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "#             outputs = model(pixel_values=images).logits\n",
    "#             outputs = F.interpolate(outputs, size=IMAGE_SIZE, mode=\"bilinear\", align_corners=False)\n",
    "#             loss = criterion(outputs, masks)\n",
    "\n",
    "#             total_val_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = total_train_loss / len(train_loader)\n",
    "#     avg_val_loss = total_val_loss / len(val_loader)\n",
    "#     print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# # Save Model\n",
    "# torch.save(model.state_dict(), \"segformer_binary.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TestDataset(test_image_dir, processor)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"segformer_binary.pth\"))\n",
    "# model.eval()\n",
    "\n",
    "# output_dir = \"./predicted_masks_segformer\"\n",
    "# os.makedirs(output_dir, exist_ok=True)  # Create directory to save masks\n",
    "\n",
    "# for images, filenames in test_loader:\n",
    "#     images = images.to(device)\n",
    "\n",
    "#     # Inference\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(pixel_values=images).logits  # (B, 2, H, W)\n",
    "#         outputs = F.interpolate(outputs, size=IMAGE_SIZE, mode=\"bilinear\", align_corners=False)\n",
    "#         predicted_masks = torch.argmax(outputs, dim=1).cpu().numpy()  # Convert to numpy array\n",
    "\n",
    "#     # Save or Display Results\n",
    "#     for i in range(len(filenames)):\n",
    "#         mask = Image.fromarray((predicted_masks[i] * 255).astype(np.uint8))  # Convert to image format\n",
    "#         mask.save(os.path.join(output_dir, filenames[i].replace(\".png\", \"_mask.png\")))\n",
    "\n",
    "# print(f\"Predicted masks saved to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
